{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "age_regression.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marisbotero/MachineLearning/blob/master/age_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSjsQJO6slTi"
      },
      "source": [
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7cju53KYGDs"
      },
      "source": [
        "#%cd drive/My\\ Drive/Colab\\ Notebooks/Datasets\n",
        "#%cd /content/drive\n",
        "!ls\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usSHyG81PmOG"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vWZUnuePpnF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a1675053-966f-4126-e478-c398465bdfa8"
      },
      "source": [
        "\n",
        "data_path = \"drive/My Drive/Colab Notebooks/Datasets/Age-Data/\"\n",
        "\n",
        "features = np.load(data_path + \"age_features.npy\")\n",
        "labels   = np.load(data_path + \"age_labels.npy\")\n",
        "\n",
        "# Randomly shuffling all samples\n",
        "x1, y1 = shuffle(features, labels)\n",
        "samples=y1.size\n",
        "y1=y1.reshape((samples,1))\n",
        "\n",
        "# Extract train and test data\n",
        "offset = int(x1.shape[0] * 0.80)\n",
        "X_train, Y_train = x1[:offset], y1[:offset]\n",
        "X_test, Y_test = x1[offset:], y1[offset:]\n",
        "Y_test = np.array(Y_test)\n",
        "Y_train = np.array(Y_train)\n",
        "\n",
        "'''\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint(features.shape)\\nprint(labels.shape)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eYHX1GOthSn"
      },
      "source": [
        "# Print dataset info\n",
        "index = 6\n",
        "plt.figure(1)\n",
        "plt.imshow(X_train[index,:,:,0])\n",
        "print (\"y = \" + str(np.squeeze(Y_train[index])))\n",
        "\n",
        "print (\"Número de ejemplos de entrenamiento: \" + str(X_train.shape[0]))\n",
        "print (\"Número de ejemplos de testing: \" + str(X_test.shape[0]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(Y_test.shape))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnpqDj1kQxiA"
      },
      "source": [
        "conv_layers = {}\n",
        "\n",
        "\n",
        "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
        "    \"\"\"\n",
        "    Create placeholders for the session\n",
        "    \n",
        "    Arguments:\n",
        "    n_H0 -- Scalar, Height of input image\n",
        "    n_W0 -- Scalar, Width of input image\n",
        "    n_C0 -- Scalar, Number of channels\n",
        "    n_y  -- Scalar, Number of ouputs\n",
        "        \n",
        "    Returns:\n",
        "    X -- Placeholder for input data   [None, n_H0, n_W0, n_C0] (dtype \"float\")\n",
        "    Y -- Placeholder for outputs data [None, n_y] (dtype \"float\")\n",
        "    \"\"\"\n",
        "\n",
        "    #### Haga su código áca ### (≈2 lines)  usar tf.placeholder\n",
        "\n",
        "    X = tf.placeholder(\"float32\", [None, - , - , - ])\n",
        "    Y = tf.placeholder(\"float32\", [None, - ])\n",
        "    \n",
        "    ### Fin ###\n",
        "    \n",
        "    return X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpnIKvpSRiid"
      },
      "source": [
        "# Creating placeholders\n",
        "X, Y = create_placeholders(64, 64, 1, 1)\n",
        "\n",
        "print (\"X = \" + str(X))\n",
        "print (\"Y = \" + str(Y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1jzWV9oRmpV"
      },
      "source": [
        "\n",
        "def initialize_parameters():\n",
        "    \"\"\"\n",
        "    Initialize network parameters. E.g.\n",
        "                        W1 : [4, 4, 1, 8]\n",
        "                        W2 : [2, 2, 8, 16]\n",
        "    Returns:\n",
        "    parameters -- Tensor dictionary with W1, W2\n",
        "    \"\"\"\n",
        "    \n",
        "    # Initial seed\n",
        "    tf.set_random_seed(1)\n",
        "        \n",
        "    ### Write your code here ### (≈2 lines) \n",
        "    \n",
        "    W1 = tf.Variable( tf.truncated_normal( [-, -, -, -], stddev=0.1 ) )\n",
        "    W2 = tf.Variable( tf.truncated_normal( [-, -, -, -], stddev=0.1 ) )\n",
        "    \n",
        "    \n",
        "    ### End ###\n",
        "    \n",
        "    parameters = { \"W1\": W1,\n",
        "                   \"W2\": W2 }\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCBXy40pRrtr"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "tf.reset_default_graph()\n",
        "\n",
        "with tf.Session() as sess_test:\n",
        "   parameters = initialize_parameters()\n",
        "   init = tf.global_variables_initializer()\n",
        "   sess_test.run(init)\n",
        "   print(\"W1 = \" + str(parameters[\"W1\"].eval()[1]))\n",
        "   print(\"W2 = \" + str(parameters[\"W2\"].eval()[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMVNuHauTxhM"
      },
      "source": [
        "\n",
        "def forward_propagation(X, parameters):\n",
        "    \"\"\"\n",
        "    \n",
        "    Forward propagation\n",
        "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
        "    \n",
        "    Arguments:\n",
        "    X -- Input placeholder (training samples) - (input size, number of examples)\n",
        "    parameters -- Dictionary containing weights to operate \"W1\", \"W2\"\n",
        "    \n",
        "    Returns:\n",
        "    Z3 -- LINEAR output \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    # Obtención de los pesos desde \"parameters\" \n",
        "    W1 = parameters['W1']\n",
        "    W2 = parameters['W2']\n",
        "    \n",
        "    #### Haga su código áca ### \n",
        "    \n",
        "    # CONV2D: stride of 1, padding 'SAME'\n",
        "    \n",
        "    Z1 = tf.nn.conv2d( - , \n",
        "                       - , \n",
        "                       strides = [1, 1, 1, 1], \n",
        "                       padding = )\n",
        "    \n",
        "    # RELU\n",
        "    \n",
        "    A1 = tf.nn.relu( - )\n",
        "    \n",
        "    # MAXPOOL: window 8x8, stride 8, padding 'SAME'\n",
        "    \n",
        "    P1 = tf.nn.max_pool( - , \n",
        "                         ksize   = [-, -, -, -], \n",
        "                         strides = [-, -, -, -], \n",
        "                         padding = - )\n",
        "    \n",
        "    # CONV2D: filters W2, stride 1, padding 'SAME'\n",
        "    \n",
        "    Z2 = tf.nn.conv2d( - , \n",
        "                       - , \n",
        "                       strides = [-, -, -, -], \n",
        "                       padding = - )\n",
        "    \n",
        "    # RELU\n",
        "    \n",
        "    A2 = tf.nn.relu( - )\n",
        "    \n",
        "    # MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
        "    \n",
        "    P2 = tf.nn.max_pool( A2, \n",
        "                         ksize   = [-, -, -, -], \n",
        "                         strides = [-, -, -, -], \n",
        "                         padding = )\n",
        "    \n",
        "    # FLATTEN\n",
        "    \n",
        "    F = tf.contrib.layers.flatten( - , \n",
        "                                   outputs_collections = None, \n",
        "                                   scope = None ) \n",
        "    \n",
        "    # FULLY-CONNECTED without non-linear activation function (not not call softmax).\n",
        "    # 1 neuron in output layer. Hint: one of the arguments should be \"activation_fn=None\" \n",
        "    \n",
        "    Z3 = tf.contrib.layers.fully_connected ( F, \n",
        "                                             1, \n",
        "                                             activation_fn = - , \n",
        "                                             normalizer_fn = None) \n",
        "\n",
        "    \n",
        "    ### End ###\n",
        "\n",
        "    return Z3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vvq1wtC6WP9Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "45d45b2c-cb2d-4648-edb4-d13d6121570b"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  np.random.seed(1)\n",
        "  X, Y = create_placeholders(-, -, -, -)\n",
        "  parameters = initialize_parameters()\n",
        "  Z3 = forward_propagation(X, parameters)\n",
        "  \n",
        "  batch_x = np.random.randn(-, -, -, -)\n",
        "  batch_y = np.random.randn(-, -)\n",
        "  \n",
        "  init = tf.global_variables_initializer()\n",
        "  sess.run(init)\n",
        "  a = sess.run( Z3, \n",
        "                feed_dict = {X: batch_x, Y: batch_y })\n",
        "  \n",
        "  print(\"Z3 = \" + str(a))\n",
        "  print(\"Z3 = \" + str(Z3.shape))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Z3 = [[0.35550475]\n",
            " [0.43929648]]\n",
            "Z3 = (?, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQO0BwX6aI8d"
      },
      "source": [
        "def compute_cost(Z3, Y):\n",
        "    \"\"\"\n",
        "    Compute cost function\n",
        "    \n",
        "    Arguments:\n",
        "    Z3 -- Output predictions (Last LINEAR unit), \n",
        "    Y  -- Output placeholder with labels. Must be same size as Z3\n",
        "\n",
        "    Returns:\n",
        "    cost - Tensor after applying cost function\n",
        "    \"\"\"\n",
        "    \n",
        "    #### Haga su código áca ### (≈2 lines)\n",
        "    \n",
        "    cost = tf.reduce_mean(tf.losses.mean_squared_error( predictions = -, labels = -))\n",
        "    \n",
        "    ### Fin ###\n",
        "    \n",
        "    return cost   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99sltmpXaupO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b8eccb2b-1f50-4ace-a358-a146c0826507"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  np.random.seed(1)\n",
        "  X, Y = create_placeholders(-, -, -, -)\n",
        "  parameters = initialize_parameters()\n",
        "  Z3 = forward_propagation(X, parameters)\n",
        "  \n",
        "  batch_x = np.random.randn(-, -, -, -)\n",
        "  batch_y = np.random.randn(-, -)\n",
        "  \n",
        "  cost = compute_cost( - ,  -)\n",
        "  init = tf.global_variables_initializer()\n",
        "  sess.run(init)\n",
        "  \n",
        "  a = sess.run( cost, \n",
        "                feed_dict = {X: batch_x, Y: batch_y })\n",
        "  \n",
        "  print(\"cost = \" + str(a))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"fully_connected/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
            "cost = 0.018818744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yP5NEkvf96T"
      },
      "source": [
        "\n",
        "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.009, num_epochs = 1, batch_size = 64, print_cost = True):\n",
        "    \"\"\"\n",
        "    \n",
        "    Complete model\n",
        "    \n",
        "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
        "    \n",
        "    Arguments:\n",
        "    X_train -- Input training data\n",
        "    Y_train -- Input training labels\n",
        "    X_test -- Input training labels\n",
        "    Y_test -- Input training labels\n",
        "    learning_rate -- learning rate\n",
        "    num_epochs -- number of epochs to train the model\n",
        "    minibatch_size -- minibatch size\n",
        "    print_cost -- (True / False) print cost after 100 epochs\n",
        "    \n",
        "    Returns:\n",
        "    train_accuracy -- Accuracy for training set (X_train)\n",
        "    test_accuracy  -- Accuracy for testing set (X_test)\n",
        "    parameters -- parameters after training stage\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    ops.reset_default_graph()                        \n",
        "    tf.set_random_seed(1)                        \n",
        "    (m, n_H0, n_W0, n_C0) = X_train.shape             \n",
        "    n_y = 1                                                            \n",
        "    costs = []                                       \n",
        "    \n",
        "    # Create placeholders\n",
        "    X, Y = create_placeholders( - , - , - , -)\n",
        "    \n",
        "    # Initialize parameters\n",
        "    parameters = initialize_parameters()\n",
        "    \n",
        "    # Forward propagation: \n",
        "    Z3 = forward_propagation( - , parameters)\n",
        "        \n",
        "    # Cost function\n",
        "    cost = compute_cost( - , - )\n",
        "    \n",
        "    # Backpropagation\n",
        "    optimizer = tf.train.AdamOptimizer().minimize( - )\n",
        "    \n",
        "    # Initialize variables\n",
        "    init = tf.global_variables_initializer()\n",
        "     \n",
        "    # Initialize session\n",
        "    with tf.Session() as sess:\n",
        "        \n",
        "        # Run init\n",
        "        sess.run(init)\n",
        "        \n",
        "        # training loop\n",
        "        for epoch in range( - ):\n",
        "\n",
        "            epoch_cost = 0.\n",
        "            total_batch = int(Y_train.shape[0]/batch_size) \n",
        "            \n",
        "            # training minibatch loop\n",
        "            for i in range(total_batch-1):\n",
        "                \n",
        "                # Create batches of data\n",
        "                batch_X= X_train[i*batch_size:(i+1)*batch_size]\n",
        "                batch_Y= Y_train[i*batch_size:(i+1)*batch_size]\n",
        "                \n",
        "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
        "                \n",
        "                # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
        "\n",
        "                _ , batch_cost = sess.run([optimizer, cost], {X: - , Y: - })\n",
        "                \n",
        "                epoch_cost += batch_cost / total_batch\n",
        "                \n",
        "\n",
        "            # Imprime el costo\n",
        "            if print_cost == True and epoch % 5 == 0:\n",
        "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
        "            if print_cost == True and epoch % 1 == 0:\n",
        "                costs.append(epoch_cost)\n",
        "        \n",
        "        \n",
        "        # Plot cost function\n",
        "        plt.figure(2)\n",
        "        plt.plot(np.squeeze(costs))\n",
        "        plt.ylabel('cost')\n",
        "        plt.xlabel('iterations (per tens)')\n",
        "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "        plt.show()\n",
        "        \n",
        "        # Estimate predictions on test data\n",
        "        error = tf.reduce_mean(tf.abs(Z3-Y))\n",
        "        train_error = 0.\n",
        "        test_error = 0.\n",
        "        total_batch = int(Y_test.shape[0]/batch_size) \n",
        "        \n",
        "        # testing minibatch loop\n",
        "        for i in range(total_batch-1):\n",
        "            batch_X= X_test[i*batch_size:(i+1)*batch_size]\n",
        "            batch_Y= Y_test[i*batch_size:(i+1)*batch_size]\n",
        "            \n",
        "            test_error = error.eval({X: - , Y: - })\n",
        "            \n",
        "            train_error += train_error / total_batch\n",
        "            test_error += test_error / total_batch\n",
        "        \n",
        "        \n",
        "        #print(\"Train Accuracy:\", train_error)\n",
        "        print(\"Test error:\", test_error)\n",
        "        \n",
        "        predictions = Z3.eval({X: X_test[index:index+2]})\n",
        "        plt.figure(1)\n",
        "        plt.imshow(X_test[index,:,:,0])\n",
        "        plt.figure(2)\n",
        "        plt.imshow(X_test[index+1,:,:,0])\n",
        "        print (\"Age = \" + str(Y_test[index:index+2]))\n",
        "        print (\"predictions = \" + str(predictions))\n",
        "                \n",
        "        return train_error, test_error, parameters\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54o_T2Rsh-eu"
      },
      "source": [
        "_, _, parameters = model(X_train, Y_train, X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}