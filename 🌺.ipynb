{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "üå∫.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMuRCydRBRCwaS98qrhclJg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marisbotero/MachineLearning/blob/master/%F0%9F%8C%BA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSxoGVpiav45"
      },
      "source": [
        "# **Como usar NLTK en Google Colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPjZ3Ng3aNJW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "488b336f-80b3-446e-ee48-851f10e4d34a"
      },
      "source": [
        "#seleccionar download [d], luego descargar el recurso de nombre \"book\"\n",
        "import nltk\n",
        "nltk.download('cess_esp')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/cess_esp.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiSiB04nbh5e"
      },
      "source": [
        "# **Expresiones Regulares**\n",
        "\n",
        "\n",
        "*   Constituyen un lenguaje estandarizado para definir cadenas de b√∫squeda de texto.\n",
        "*   Libreria de operaciones con  expresiones regulares de Python [re](https://docs.python.org/3/library/re.html)\n",
        "*   Reglas para escribir expresiones regulares [Wiki](https://es.wikipedia.org/wiki/Expresi√≥n_regular)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDdHJjjYa6Pu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f6ed90ab-4112-4ac8-aace-8e8db5583760"
      },
      "source": [
        "# spanish Corpus: https://mailman.uib.no/public/corpora/2007-October/005448.html\n",
        "import re\n",
        "corpus = nltk.corpus.cess_esp.sents() \n",
        "print(corpus)\n",
        "print(len(corpus))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['El', 'grupo', 'estatal', 'Electricit√©_de_France', '-Fpa-', 'EDF', '-Fpt-', 'anunci√≥', 'hoy', ',', 'jueves', ',', 'la', 'compra', 'del', '51_por_ciento', 'de', 'la', 'empresa', 'mexicana', 'Electricidad_√Åguila_de_Altamira', '-Fpa-', 'EAA', '-Fpt-', ',', 'creada', 'por', 'el', 'japon√©s', 'Mitsubishi_Corporation', 'para', 'poner_en_marcha', 'una', 'central', 'de', 'gas', 'de', '495', 'megavatios', '.'], ['Una', 'portavoz', 'de', 'EDF', 'explic√≥', 'a', 'EFE', 'que', 'el', 'proyecto', 'para', 'la', 'construcci√≥n', 'de', 'Altamira_2', ',', 'al', 'norte', 'de', 'Tampico', ',', 'prev√©', 'la', 'utilizaci√≥n', 'de', 'gas', 'natural', 'como', 'combustible', 'principal', 'en', 'una', 'central', 'de', 'ciclo', 'combinado', 'que', 'debe', 'empezar', 'a', 'funcionar', 'en', 'mayo_del_2002', '.'], ...]\n",
            "6030\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4qZ84LCdNk1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "efa72acb-c428-498f-e60a-3b80a1cc94c7"
      },
      "source": [
        "#for l in corpus:\n",
        "  #for w in l\n",
        "    ## \n",
        "\n",
        "flatten = [w for l in corpus for w in l]\n",
        "print(flatten[:20])\n",
        "print(len(flatten))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['El', 'grupo', 'estatal', 'Electricit√©_de_France', '-Fpa-', 'EDF', '-Fpt-', 'anunci√≥', 'hoy', ',', 'jueves', ',', 'la', 'compra', 'del', '51_por_ciento', 'de', 'la', 'empresa', 'mexicana']\n",
            "192685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnnG4Yioitbp"
      },
      "source": [
        "### **Estructura de la funcion re.search()**\n",
        "```\n",
        "# Determina si el patron de b√∫squeda p esta contenido en la cadena s\n",
        "re.seach(p, s)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCSPZlCFVVTf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "80cf2d03-75f1-49d3-b452-6852cebe271b"
      },
      "source": [
        "# Meta-caracteres b√°sicos\n",
        "arr = [w for w in flatten if re.search('es', w)]\n",
        "arr[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['estatal', 'jueves', 'empresa', 'centrales', 'francesa']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP-Vtd62jGaP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d4131905-f7e3-4870-9231-85ace1ca8086"
      },
      "source": [
        "arr = [w for w in flatten if re.search('es$', w)]\n",
        "arr[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['jueves', 'centrales', 'millones', 'millones', 'd√≥lares']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ08vKvKjRQU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "78d569d4-7108-478d-8884-dbb38f525940"
      },
      "source": [
        "arr = [w for w in flatten if re.search('^es', w)]\n",
        "arr[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['estatal', 'es', 'esta', 'esta', 'eso']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QltWUUQhj0as",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "90b94d53-449c-484e-fb63-7e5619050451"
      },
      "source": [
        "arr = [w for w in flatten if re.search('^..j..t..$', w)]\n",
        "arr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tajantes']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhPectTIj7KQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "57fc55c2-2260-434b-df0c-11120fa7839c"
      },
      "source": [
        "#Rangos [a-z], [A-Z], [0-9]\n",
        "arr = [w for w in flatten if re.search('^[ghi][mno][jlk][def]$', w)]\n",
        "arr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['golf', 'golf']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63AMmVplxmoX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "6e52d96a-f0bc-492e-f6c4-6ef773694953"
      },
      "source": [
        "#Clausuras *, * (Kleene closures)\n",
        "arr = [w for w in flatten if re.search('^(no)*', w)]\n",
        "arr[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['El',\n",
              " 'grupo',\n",
              " 'estatal',\n",
              " 'Electricit√©_de_France',\n",
              " '-Fpa-',\n",
              " 'EDF',\n",
              " '-Fpt-',\n",
              " 'anunci√≥',\n",
              " 'hoy',\n",
              " ',']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rgucyYHmhv2"
      },
      "source": [
        "## **Normalizaci√≥n de Texto** (como aplicaci√≥n de las expresiones regulares)\n",
        "\n",
        "## **Tokenizaci√≥n:** Es el proceso mediante el cual se sub-divide una cadena de texto en unidades lingu√≠sticas minimas (palabras)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0qOTxZqmTTu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "08084ec9-f34e-4f0a-cb85-ae6032202b38"
      },
      "source": [
        "texto = \"\"\" siempre he sido de amores anacr√≥nicos: por esto mi obsesi√≥n con las cartas. \n",
        "Hay algo sobre la necesidad, la urgencia con la que se escriben y la intimidad que encierran, \n",
        "casi como si cada palabra fuera escrita a modo de confesi√≥n. \n",
        "Jos√© Cede√±o dice que escribimos cartas por dos razones:\n",
        "‚Äúpara que un ‚Äòotro‚Äô lea lo que no sabe, y para que uno se desprenda de lo que siempre supo‚Äù y yo le creo, \n",
        "pero tambi√©n creo firmemente que son mucho m√°s que eso. \n",
        "Lejos de ser un medio de comunicaci√≥n pasado de moda, \n",
        "las cartas son un boceto del momento presente y aunque vienen de una experiencia personal, \n",
        "pueden llegar a reflejar un sentimiento colectivo. \n",
        "Vernos reflejados en las palabras ajenas (o m√°s bien prestadas) \n",
        "hace que entendamos que en el fondo todos somos iguales; \n",
        "somos humanos y navegamos sobre el mismo miedo. Por esto hago este proyecto son cartas sin remitente ni destinatario \n",
        "(para que quien las encuentre, las use como vea necesario) \n",
        "como una invitaci√≥n a construir puentes de palabras. \n",
        "Ojal√° en ellas se encuentren y \n",
        "nos demos cuenta de que en medio de la soledad, no estamos tan solos. ...\"\"\"\n",
        "print(texto)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " siempre he sido de amores anacr√≥nicos: por esto mi obsesi√≥n con las cartas. \n",
            "Hay algo sobre la necesidad, la urgencia con la que se escriben y la intimidad que encierran, \n",
            "casi como si cada palabra fuera escrita a modo de confesi√≥n. \n",
            "Jos√© Cede√±o dice que escribimos cartas por dos razones:\n",
            "‚Äúpara que un ‚Äòotro‚Äô lea lo que no sabe, y para que uno se desprenda de lo que siempre supo‚Äù y yo le creo, \n",
            "pero tambi√©n creo firmemente que son mucho m√°s que eso. \n",
            "Lejos de ser un medio de comunicaci√≥n pasado de moda, \n",
            "las cartas son un boceto del momento presente y aunque vienen de una experiencia personal, \n",
            "pueden llegar a reflejar un sentimiento colectivo. \n",
            "Vernos reflejados en las palabras ajenas (o m√°s bien prestadas) \n",
            "hace que entendamos que en el fondo todos somos iguales; \n",
            "somos humanos y navegamos sobre el mismo miedo. Por esto hago este proyecto son cartas sin remitente ni destinatario \n",
            "(para que quien las encuentre, las use como vea necesario) \n",
            "como una invitaci√≥n a construir puentes de palabras. \n",
            "Ojal√° en ellas se encuentren y \n",
            "nos demos cuenta de que en medio de la soledad, no estamos tan solos. ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdLIv_YgmvLl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b4a8a925-06fc-4bb9-e075-5dfb83a57ce5"
      },
      "source": [
        "# Caso 1: tokenizacion m√°s simple: por espacios vacios !\n",
        "print(re.split(r' ', texto))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', 'Fuimos', 'una', 'novela', 'que', 'tan\\n', 'solo', 'pudo', 'ser', 'poema', '...']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAiJfS7Lm31V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d90fa983-7340-41c6-f7fc-64080c2d8160"
      },
      "source": [
        "# Caso 2: tokenizaci√≥n usando expresiones regulares\n",
        "print(re.split(r'[ \\t\\n]+', texto))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', 'Fuimos', 'una', 'novela', 'que', 'tan', 'solo', 'pudo', 'ser', 'poema', '...']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkkBYLzSm7Qt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "aecb6dd1-37dc-40f3-9a4d-02d80208eba5"
      },
      "source": [
        "# RegEx reference: \\W -> all characters other than letters, digits or underscore\n",
        "print(re.split(r'[ \\W\\t\\n]+', texto))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', 'Cuando', 'sea', 'el', 'rey', 'del', 'mundo', 'imaginaba', '√©l', 'en', 'su', 'cabeza', 'no', 'tendr√©', 'que', 'preocuparme', 'por', 'estas', 'bobadas', 'Era', 'solo', 'un', 'ni√±o', 'de', '7', 'a√±os', 'pero', 'pensaba', 'que', 'podr√≠a', 'ser', 'cualquier', 'cosa', 'que', 'su', 'imaginaci√≥n', 'le', 'permitiera', 'visualizar', 'en', 'su', 'cabeza', '']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOgYEslS4fdM"
      },
      "source": [
        "## **Tokenizador de NLTK**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLBTKB20m-3O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d5dec66b-ad66-49a1-fd79-a6643c23e3a2"
      },
      "source": [
        "# nuestra antigua regex no funciona en este caso: \n",
        "texto = 'como me consigo alg√∫n motivo pa que los amaneceres que tu ves'\n",
        "print(re.split(r'[ \\W\\t\\n]+', texto))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['En', 'los', 'E', 'U', 'esa', 'postal', 'vale', '15', '50', '']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQTXiZ-b4sO2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9a493aad-d60d-4991-e075-3c1955851a18"
      },
      "source": [
        "pattern = r'''(?x)                 # set flag to allow verbose regexps\n",
        "              (?:[A-Z]\\.)+         # abbreviations, e.g. U.S.A.\n",
        "              | \\w+(?:-\\w+)*       # words with optional internal hyphens\n",
        "              | \\$?\\d+(?:\\.\\d+)?%? # currency and percentages, e.g. $12.40, 82%\n",
        "              | \\.\\.\\.             # ellipsis\n",
        "              | [][.,;\"'?():-_`]   # these are separate tokens; includes ], [\n",
        "'''\n",
        "nltk.regexp_tokenize(texto, pattern)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['En', 'los', 'E.U.', 'esa', 'postal', 'vale', '$15.50', '...']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3Ac0Jol9rvk"
      },
      "source": [
        "## **Lematizaci√≥n:** Proceso para encontrar la ra√≠z lingu√≠stica de una palabra\n",
        "\n",
        "*   Derivaci√≥n (stemming) : lematizaci√≥n simple"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd701QnT5631",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "c69899a8-e17b-4f16-c98a-7415f45c24e0"
      },
      "source": [
        "# Derivaci√≥n simple\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "SnowballStemmer.languages"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('arabic',\n",
              " 'danish',\n",
              " 'dutch',\n",
              " 'english',\n",
              " 'finnish',\n",
              " 'french',\n",
              " 'german',\n",
              " 'hungarian',\n",
              " 'italian',\n",
              " 'norwegian',\n",
              " 'porter',\n",
              " 'portuguese',\n",
              " 'romanian',\n",
              " 'russian',\n",
              " 'spanish',\n",
              " 'swedish')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm_cNzmg9vDm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}